# Udemy Course: Machine Learning with Javascript by Stephen Grider

* [Course Link](https://www.udemy.com/machine-learning-with-javascript/)
* [Course Repo](https://github.com/StephenGrider/MLCasts)

## Section 1 - What is Machine Learning

### Lecture 2 - Solving Machine Learning Problems

* ML can do predicions based on historical data. e.g if it rain 240mm what the flood damage will there be
* The ML Problem Solving Process
	* Identify data that is relevant to the problem
	* Assemble a set of data related to the problem we're trying to solve
	* Decide on the type of output we are predicting
	* Based on type of output, pick an algorithm that will determine a correlations between our 'features' and 'labels'
	* Use model generated by algorithm to make a prediction
* For our example problem 'annual rainfall' is the feature or independent variable. Flood damage costs is the dependent variable 'label'
* in this course we will see how we can collect data format it and prepare it for ML
* we will assume we have no data. data can come from videos, newspapers, websites
* flood repair spending can come from budget reports. 
* all is assembled in a table

### Lecture 3 - A Complete Walkthrough

* Value of Labels are discrete set? Classification
* Value of Labes is continuous? Regression
* the example problem about floods is a regression problem (we predict money)
* Some takeaway points
	* Features are categories of data points that affect the value of labels
	* Datasets almost always need cleanup and formatting
	* Regression for continuous vals, Classification for diescrete
	* Many many different ML algorithms exist each with pros and cons anf or different type of problems.
	* models relate the value of features to the value of labels

### Lecture 4 - App Setup

* we go to [Github Starter Projects](https://github.com/StephenGrider/MLKits) and download them in our course workspace
* we go to '/MLKits/plinko'
* we open 'index.html'

### Lecture 5 - Problem Outline

* what we see is a game that puts (randomly?) disks in buckets increasing their counter.
* we will use it to build a dataset trying to predict in which bucket the ball will end to given the drop point

### Lecture 6 - Identifying Relevant Data

* apart from the priamry feature (drop position) we identify 2 minor features. ball size and bonciness. both are randonly selected between a configurable range of values

### Lecture 7 - Dataset Structures

* the app offers a lot of ways to record our tries and collect data (dataset)
* In JS datasets can be:
	* Arrays of objects eg `[{dropPosition: 300, bonciness: 0.4, ballSize: 16, bucket: 4}]`
	* Nested Arrays [[300,0,4,16,4],[350,0.4,35,5],[416,0.4,16,4]]. Indices are Important
* we open 'score.js'. it has 2 method signatures one to collect the data set and one to run the analyzsis to predict

### Lecture 8 - Recording Observation Data

* we flesh out 'onScoreUpdate' a callback  called everytime a round ends to collect data
```
const outputs = [];

function onScoreUpdate(dropPosition, bounciness, size, bucketLabel) {
  // Ran every time a balls drops into a bucket
  outputs.push([dropPosition,bounciness,size,bucketLabel]);
  console.log(outputs);
}
```
* we test and see an evergroing nested array

### Lecture 9 - What Type of Problem?

* our problem is clearly a Classification
* our classification algorithm of choice is K-Nearest Neighbor (knn) is based on clustering

## Section 2 - Algorithm Overview

### Lecture 10 - How K-Nearest Neighbor Works

* Thought Experiment: what wqould happen if we dropped the ball 10 times from almost the same spot (300px)? 
* K-Nearest Neighbor (with one independent variable)
	* Drop a ball a bunch of times all around the board, record which bucket it goes to
	* For each observation subtract drop point from 300px, take absolute value
	* Sort ther results from least to greatest
	* Look at the 'k' top  records. What was the most common bucket?
	Whichever bucket came up most frequently is the one ours will probably go to

### Lecture 11 - Lodash Review

* we will use [lodash](https://lodash.com/docs/). a JS utility library with lots of methods for arrays, objects etc
* we use JS interpreter tool [JSPlaygrounds](https://stephengrider.github.io/JSPlaygrounds/) to experiment with code
* if we have a 4x2 nested array and we want to sort it by the row second element we can use stortBy selecting the element based on which we want to sort
```
const numbers = [[10,5],[17,2],[34,1],[60,-5]];
const sorted = _.sortBy(numbers, row => row[1])
```
* we map through the sorted array to extract second element `const mapped = _.map(sorted, row => row[1]);`
* we see a pattern forming where we use the previous result as input for next method .... function chaining maybe??? '_.chain' allows to chain lodash methods passing in result
```
_.chain(numbers)
	.sortBy(row=>row[1])
	.map(row=>row[1])
	.value();
```
* note that we omit the first argument as its implicitly passe don. vlaue() stops the chain adn returns the result

### Lecture 12 - Implementing KNN

* we start implementing KNN in JS using lodash in JSPlaygrounds
* we start by defining a hardcoded dataset as nested array
```
const outputs = [
	[10, .5, 16, 1].
  [200, .5, 16, 4],
  [350, .5, 16, 4],
  [600, .5, 16, 5]
];
```
* for e ach observation, we will subtract droppoint from 300px, and take the absolute value. we will use map. our result table will have to datapoints per observation. droppoint and bucket
* we put our distance calculation in a helper
```
const predictionPoint = 300;

const distance = (point) => {
	return Math.abs(point - predictionPoint);
};
```
* we implement step 1 
```

_.chain(outputs)
  .map(row => [distance(row[0]),row[3]])
```
* step 2 is to sort results from least to greatest. we use sortBy